# [Java并发和多线程教程]([http://tutorials.jenkov.com/java-concurrency/index.html](http://tutorials.jenkov.com/java-concurrency/index.html))

Java *并发性*是一个涵盖Java平台上的多线程，并发和并行性的术语。其中包括Java并发工具，问题和解决方案。该Java并发教程涵盖了多线程的核心概念，并发构造，并发问题，成本以及与Java中多线程相关的好处。

## 什么是多线程？

多线程意味着您在同一应用程序中具有多个*执行线程*。线程就像执行应用程序的独立CPU。因此，多线程应用程序就像具有多个CPU同时执行代码不同部分的应用程序。

![](http://tutorials.jenkov.com/images/java-concurrency/introduction-1.png)

线程不等于CPU。通常，单个CPU将在多个线程之间共享其执行时间，并在给定的时间量内在每个线程的执行之间进行切换。也可以让应用程序的线程由不同的CPU执行。

![](http://tutorials.jenkov.com/images/java-concurrency/introduction-2.png)

## 为什么要多线程？

为什么要在应用程序中使用多线程有几个原因。多线程的一些最常见原因是：

- 更好地利用单个CPU。
- 更好地利用多个CPU或CPU内核。
- 关于响应性的更好的用户体验。
- 关于公平的更好的用户体验。

我将在以下各节中详细解释每个原因。

### 更好地利用单个CPU

最常见的原因之一是能够更好地利用计算机中的资源。例如，如果一个线程正在等待对通过网络发送的请求的响应，则另一线程可以同时使用CPU来执行其他操作。此外，如果计算机具有多个CPU，或者CPU具有多个执行核心，则多线程还可以帮助您的应用程序利用这些额外的CPU核心。

### 更好地利用多个CPU或CPU内核

如果计算机包含多个CPU或CPU包含多个执行核心，则您需要为应用程序使用多个线程才能使用所有CPU或CPU核心。单个线程最多只能使用一个CPU，如上所述，有时甚至不能完全利用单个CPU。

### 关于响应能力的更好的用户体验

使用多线程的另一个原因是为了提供更好的用户体验。例如，如果您单击GUI中的按钮，并导致通过网络发送请求，那么哪个线程执行此请求就很重要。如果使用的线程也正在更新GUI，则在GUI线程等待请求响应时，用户可能会遇到GUI“挂起”的情况。取而代之的是，这样的请求可以由背景线程执行，因此GUI线程可以自由地同时响应其他用户请求。

### 关于公平的更好的用户体验

第四个原因是在用户之间更公平地共享计算机资源。例如，假设一台服务器接收来自客户端的请求，并且只有一个线程来执行这些请求。如果客户端发送的请求要花费很长时间才能处理，则所有其他客户端的请求都必须等待，直到一个请求完成。通过使每个客户端的请求都由其自己的线程执行，则没有一个任务可以完全垄断CPU。

## 多线程与多任务

过去，一台计算机只有一个CPU，并且一次只能执行一个程序。大多数小型计算机的功能实际上不足以同时执行多个程序，因此没有尝试过。公平地讲，许多大型机系统能够一次执行多个程序的时间比个人计算机长得多。

### 多任务

后来出现了多任务处理，这意味着计算机可以同时执行多个程序（AKA任务或进程）。但是，这并不是真正的“同时”。单个CPU在程序之间共享。操作系统将在运行的程序之间进行切换，并在切换之前执行每个程序一会儿。

随着多任务处理，软件开发人员面临着新的挑战。程序不再假定拥有所有可用的CPU时间，也不拥有所有的内存或任何其他计算机资源。一个“好公民”程序应释放不再使用的所有资源，以便其他程序可以使用它们。

### 多线程

后来出现了多线程，这意味着您可以在同一程序中拥有多个执行线程。可以将执行线程视为执行程序的CPU。当您有多个线程执行同一程序时，就像在同一程序中执行多个CPU。

## 多线程很难

多线程是提高某些类型程序性能的好方法。但是，多线程处理比多任务处理更具挑战性。这些线程在同一程序中执行，因此同时在读取和写入相同的内存。这可能会导致在单线程程序中看不到的错误。在单个CPU机器上可能看不到其中一些错误，因为两个线程从未真正“同时”执行。但是，现代计算机配备了多核CPU，甚至还配备了多个CPU。这意味着可以由单独的内核或CPU同时执行单独的线程。

![](http://tutorials.jenkov.com/images/java-concurrency/java-concurrency-tutorial-introduction-1.png)

如果一个线程在另一个线程写入内存位置时读取了一个内存位置，那么第一个线程最终将读取什么值？旧值？第二个线程写的值？还是两者之间混合的值？或者，如果两个线程正在同时写入同一内存位置，那么完成后将剩下什么值？由第一个线程写的值？第二个线程写的值？还是两个值的混合编写？

没有适当的预防措施，任何这些结果都是可能的。该行为甚至是不可预测的。结果可能会不时改变。因此，作为开发人员，重要的是要知道如何采取正确的预防措施-意味着学习控制线程如何访问共享资源（如内存，文件，数据库等）。这是本Java并发性教程解决的主题之一。

## Java中的多线程和并发

Java是最早使开发人员可以使用多线程的语言之一。Java从一开始就具有多线程功能。因此，Java开发人员经常会遇到上述问题。这就是我在Java并发上编写此线索的原因。谨此提醒自己，以及可能从中受益的其他Java开发人员。

本教程主要关注Java中的多线程，但是多线程中发生的某些问题类似于多任务和分布式系统中发生的问题。因此，对多任务和分布式系统的引用也可能出现在此线索中。因此，单词“并发”而不是“多线程”。

## 并发模型

第一个Java *并发模型*假定在同一应用程序中执行的多个线程也将共享对象。这种类型的并发模型通常称为“共享状态并发模型”。许多并发语言构造和实用程序都旨在支持此并发模型。

但是，自从编写第一本Java并发书籍以来，甚至自Java 5并发实用工具发布以来，并发体系结构和设计领域已经发生了很多事情。

共享状态并发模型导致许多并发问题，这些问题很难优雅地解决。因此，被称为“无共享”或“分离状态”的替代并发模型已经普及。在单独的状态并发模型中，线程不共享任何对象或数据。这避免了共享状态并发模型的许多并发访问问题。

出现了新的异步“独立状态”平台和工具包，例如Netty，Vert.x和Play / Akka和Qbit。新的非阻塞并发算法已经发布，并且新的非阻塞工具（例如LMax Disrupter）已添加到我们的工具箱中。Java 7中的Fork and Join框架和Java 8中的collection stream API引入了新的函数式编程并行性。

通过所有这些新开发，现在是时候更新本Java Concurrency教程了。因此，本教程再次**进行中**。只要有时间编写新教程，它们就会发布。



## Java并发学习指南

如果您不熟悉Java并发，建议您遵循以下学习计划。您也可以在此页面左侧的菜单中找到所有主题的链接。

通用并发和多线程理论：

- [多线程的好处](http://tutorials.jenkov.com/java-concurrency/benefits.html)
- [多线程成本](http://tutorials.jenkov.com/java-concurrency/costs.html)
- [并发模型](http://tutorials.jenkov.com/java-concurrency/concurrency-models.html)
- [同线程](http://tutorials.jenkov.com/java-concurrency/same-threading.html)
- [并发与并行](http://tutorials.jenkov.com/java-concurrency/concurrency-vs-parallelism.html)

Java并发基础知识：

- [创建和启动Java线程](http://tutorials.jenkov.com/java-concurrency/creating-and-starting-threads.html)
- [比赛条件和关键部分](http://tutorials.jenkov.com/java-concurrency/race-conditions-and-critical-sections.html)
- [线程安全和共享资源](http://tutorials.jenkov.com/java-concurrency/thread-safety.html)
- [线程安全性和不变性](http://tutorials.jenkov.com/java-concurrency/thread-safety-and-immutability.html)
- [Java内存模型](http://tutorials.jenkov.com/java-concurrency/java-memory-model.html)
- [Java同步块](http://tutorials.jenkov.com/java-concurrency/synchronized.html)
- [Java易失关键字](http://tutorials.jenkov.com/java-concurrency/volatile.html)
- [Java ThreadLocal](http://tutorials.jenkov.com/java-concurrency/threadlocal.html)
- [Java线程信令](http://tutorials.jenkov.com/java-concurrency/thread-signaling.html)

Java并发性的典型问题：

- [僵局](http://tutorials.jenkov.com/java-concurrency/deadlock.html)
- [防止死锁](http://tutorials.jenkov.com/java-concurrency/deadlock-prevention.html)
- [饥饿与公平](http://tutorials.jenkov.com/java-concurrency/starvation-and-fairness.html)
- [嵌套监视器锁定](http://tutorials.jenkov.com/java-concurrency/nested-monitor-lockout.html)
- [滑倒条件](http://tutorials.jenkov.com/java-concurrency/slipped-conditions.html)

Java并发构造可帮助解决上述问题：

- [Java锁](http://tutorials.jenkov.com/java-concurrency/locks.html)
- [Java中的读/写锁](http://tutorials.jenkov.com/java-concurrency/read-write-locks.html)
- [重入锁定](http://tutorials.jenkov.com/java-concurrency/reentrance-lockout.html)
- [信号量](http://tutorials.jenkov.com/java-concurrency/semaphores.html)
- [阻塞队列](http://tutorials.jenkov.com/java-concurrency/blocking-queues.html)
- [线程池](http://tutorials.jenkov.com/java-concurrency/thread-pools.html)
- [比较和交换](http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html)

Java并发实用程序（java.util.concurrent）：

- [Java并发实用程序-java.util.concurrent](http://tutorials.jenkov.com/java-util-concurrent/index.html)

进一步的主题：

- [同步器的解剖](http://tutorials.jenkov.com/java-concurrency/anatomy-of-a-synchronizer.html)
- [非阻塞算法](http://tutorials.jenkov.com/java-concurrency/non-blocking-algorithms.html)
- [阿姆达尔定律](http://tutorials.jenkov.com/java-concurrency/amdahls-law.html)
- [参考文献](http://tutorials.jenkov.com/java-concurrency/references.html)



# 多线程的好处

多线程的最大好处是：

- 更高的CPU利用率。
- 在某些情况下，程序设计更简单。
- 响应速度更快的程序。
- 在不同任务之间更公平地分配CPU资源。

## 更好的CPU使用率

想象一个应用程序从本地文件系统读取和处理文件。假设从磁盘读取af文件需要5秒钟，而处理则需要2秒钟。然后处理两个文件

```
  5秒钟读取文件A
  2秒处理文件A
  5秒钟读取文件B
  2秒处理文件B
-----------------------
 总共14秒
```

从磁盘读取文件时，大部分的CPU时间都花在等待磁盘读取数据上。在这段时间内，CPU几乎处于空闲状态。它可能正在做其他事情。通过更改操作顺序，可以更好地利用CPU。查看以下顺序：

```
  5秒钟读取文件A
  5秒读取文件B + 2秒处理文件A
  2秒处理文件B
-----------------------
 总共12秒
```

CPU等待读取第一个文件。然后，它开始读取第二个文件。当计算机的IO组件读取第二个文件时，CPU处理第一个文件。请记住，在等待从磁盘读取文件时，CPU大部分处于空闲状态。

通常，CPU在等待IO时可以做其他事情。不必是磁盘IO。它也可以是网络IO，也可以是来自计算机用户的输入。网络和磁盘IO通常比CPU和内存IO慢很多。

## 程序设计更简单

如果要在单线程应用程序中手动编写上述读取和处理的顺序，则必须跟踪每个文件的读取和处理状态。相反，您可以启动两个线程，每个线程仅读取和处理一个文件。这些等待线程将在等待磁盘读取其文件时被阻止。在等待时，其他线程可以使用CPU处理已读取的文件部分。结果是磁盘始终保持忙碌状态，将各种文件读入内存。这样可以更好地利用磁盘和CPU。编程也更容易，因为每个线程只需要跟踪一个文件即可。

## 更多响应程序

将单线程应用程序转换为多线程应用程序的另一个共同目标是实现响应速度更快的应用程序。想象一个服务器应用程序在某个端口上侦听传入的请求。收到请求后，它将处理该请求，然后返回监听。服务器循环如下所示：

```
  而（服务器处于活动状态）{
    听请求
    处理要求
  }
```

如果请求需要很长时间才能处理，则在此期间内没有新客户端可以将请求发送到服务器。只有在服务器正在侦听时，才能接收请求。

另一种设计是侦听线程将请求传递给工作线程，然后立即返回侦听。工作线程将处理该请求，并将回复发送给客户端。该设计如下所示：

```
  而（服务器处于活动状态）{
    听请求
    手动请求工人线程
  }
```

这样，服务器线程将尽快恢复监听。因此，更多的客户端可以将请求发送到服务器。服务器变得更加敏感。

桌面应用程序也是如此。如果单击启动长任务的按钮，并且执行任务的线程是更新窗口，按钮等的线程，则任务执行时应用程序将显示为无响应。而是可以将任务移交给工作线程。当工作线程忙于任务时，窗口线程可以自由响应其他用户请求。当工作线程完成时，它向窗口线程发出信号。然后，窗口线程可以使用任务结果更新应用程序窗口。具有工作线程设计的程序将对用户响应更快。

## 更公平地分配CPU资源

假设有一个服务器正在接收来自客户端的请求。然后想象一下，其中一个客户端发送了一个处理时间很长的请求，例如10秒。如果服务器使用单个线程处理所有任务，则处理缓慢的请求之后的所有请求将被迫等待，直到处理完完整的请求为止。

通过在多个线程之间划分CPU时间并在线程之间进行切换，CPU可以在多个请求之间更公平地共享其执行时间。这样，即使其中一个请求较慢，也可以与较慢的请求同时执行处理速度更快的其他请求。当然，这意味着执行慢速请求的速度甚至会更慢，因为它不会仅将CPU分配给处理它。但是，其他请求将不得不等待更短的时间来处理，因为它们不必等待缓慢的任务完成才可以处理它们。如果只有慢请求要处理，则仍可以将CPU单独分配给慢任务。



# 多线程成本

从单线程应用程序到多线程应用程序不仅会带来好处。它也有一些费用。不要仅仅因为可以就启用多线程应用程序。您应该有一个好主意，即这样做所带来的收益大于成本。如有疑问，请尝试评估应用程序的性能或响应能力，而不仅仅是猜测。

## 更复杂的设计

尽管多线程应用程序的某些部分比单线程应用程序简单，但其他部分则更复杂。由多个线程访问共享数据执行的代码需要特别注意。线程交互远非总是那么简单。错误线程同步引起的错误很难检测，重现和修复。

## 上下文切换开销

当CPU从执行一个线程切换到执行另一个线程时，CPU需要保存当前线程的本地数据，程序指针等，并加载要执行的下一个线程的本地数据，程序指针等。此开关称为“上下文开关”。CPU从在一个线程的上下文中执行切换为在另一个线程的上下文中执行。

上下文切换并不便宜。您不想在线程之间进行不必要的切换。

您可以在Wikipedia上阅读有关上下文切换的更多信息：

[http://en.wikipedia.org/wiki/Context_switch](http://en.wikipedia.org/wiki/Context_switch)

## 资源消耗增加

线程需要计算机中的一些资源才能运行。除了CPU时间外，线程还需要一些内存来保留其本地堆栈。它还可能会占用操作系统中管理线程所需的一些资源。尝试创建一个程序，该程序创建的100个线程除了等待外什么也不做，并查看应用程序在运行时需要占用多少内存。



# 并发模型

可以使用不同的*并发模型*来实现并发系统。一*并发模型*指定的系统协作线程如何完成他们给予的任务。不同的并发模型以不同的方式拆分任务，线程可以以不同的方式进行通信和协作。本并发模型教程将更深入地介绍撰写本文时（2015年至2019年）使用的最受欢迎的并发模型。

## 并发模型和分布式系统的相似性

本文中描述的并发模型类似于分布式系统中使用的不同体系结构。在并发系统中，不同的线程彼此通信。在分布式系统中，不同的进程相互通信（可能在不同的计算机上）。线程和进程本质上非常相似。这就是为什么不同的并发模型通常看起来与不同的分布式系统体系结构相似的原因。

当然，分布式系统还面临着额外的挑战，即网络可能会失败，或者远程计算机或进程出现故障等。但是，如果CPU发生故障，网卡发生故障，磁盘发生故障，则在大型服务器上运行的并发系统可能会遇到类似的问题。失败的可能性可能会更低，但理论上仍会发生。

由于并发模型与分布式系统体系结构相似，因此它们经常可以相互借鉴。例如，用于在工作人员（线程）之间分配工作的模型通常类似于[分布式系统中](http://tutorials.jenkov.com/software-architecture/load-balancing.html)的[负载平衡](http://tutorials.jenkov.com/software-architecture/load-balancing.html)模型。错误处理技术（例如日志记录，故障转移，任务的幂等）也是如此。





## 共享状态与分离状态

并发模型的一个重要方面是，组件和线程是设计为在线程之间共享状态，还是要具有从未在线程之间共享的单独状态。

*共享状态*意味着系统中的不同线程将在它们之间共享某些状态。通过*状态*是指一些数据，通常是一个或多个对象或相似。当线程共享状态时，可能会出现[争用条件](http://tutorials.jenkov.com/java-concurrency/race-conditions-and-critical-sections.html) 和[死锁](http://tutorials.jenkov.com/java-concurrency/deadlock.html)等问题。当然，这取决于线程如何使用和访问共享对象。





*分开的状态*意味着系统中的不同线程在它们之间不共享任何状态。万一不同的线程需要通信，它们可以通过在它们之间交换不可变对象或通过在它们之间发送对象（或数据）的副本来进行通信。因此，当没有两个线程写入同一对象（数据/状态）时，可以避免大多数常见的并发问题。





使用单独的状态并发设计通常可以使代码的某些部分更易于实现和推理，因为您知道只有一个线程将写入给定对象。您不必担心并发访问该对象。但是，使用单独的状态并发性，您可能需要更全面地考虑应用程序设计。我觉得这是值得的。我个人更喜欢单独的状态并发设计。





## 平行工人

第一个并发模型是我所说的*并行工作器*模型。传入的工作分配给不同的工人。这是说明并行工作程序并发模型的图：





在并行工人并发模型中，委托人将传入的作业分配给不同的工人。每个工人完成全部工作。这些工作程序并行工作，在不同的线程中运行，并可能在不同的CPU上运行。

如果在汽车制造厂实施并行工人模型，则每辆汽车将由一名工人生产。工人将获得要制造的汽车的规格，并会从头到尾制造所有东西。

并行工作程序并发模型是Java应用程序中最常用的并发模型（尽管正在改变）。[java.util.concurrent Java包](http://tutorials.jenkov.com/java-util-concurrent/index.html) 中的许多并发实用[程序](http://tutorials.jenkov.com/java-util-concurrent/index.html)都是设计用于此模型的。您还可以在Java Enterprise Edition应用程序服务器的设计中看到此模型的痕迹。





## 平行工人优势

并行工作程序并发模型的优点是易于理解。为了增加应用程序的并行化，您只需添加更多工作程序即可。

例如，如果您正在实施Web搜寻器，则可以使用不同数量的工作程序来搜寻一定数量的页面，并查看哪个数字提供了最短的总搜寻时间（意味着最高的性能）。由于Web爬网是一项IO密集型工作，您最终可能会为计算机中的每个CPU /内核使用几个线程。每个CPU一个线程太少了，因为它在等待数据下载时会处于许多空闲状态。





## 平行工人的劣势

但是，并行工作程序并发模型具有一些隐藏在简单表面下的缺点。我将在以下各节中解释最明显的缺点。





### 共享状态会变得复杂

实际上，并行工作程序并发模型比上面说明的要复杂一些。共享工作者经常需要访问内存或共享数据库中的某种共享数据。下图显示了如何使并行工作器并发模型复杂化：





这种共享状态中的某些处于诸如工作队列之类的通信机制中。但是这种共享状态中的一些是业务数据，数据缓存，与数据库的连接池等。

一旦共享状态潜入并行工作程序并发模型中，它就会开始变得复杂。线程需要以确保一个线程的更改对其他线程可见的方式访问共享数据（将其推送到主内存中，而不仅仅是停留在执行该线程的CPU的CPU缓存中）。线程需要避免[争用条件](http://tutorials.jenkov.com/java-concurrency/race-conditions-and-critical-sections.html)， [死锁](http://tutorials.jenkov.com/java-concurrency/deadlock.html)和许多其他共享状态并发问题。

此外，当线程在访问共享数据结构时互相等待时，并行化的一部分会丢失。许多并发数据结构正在阻塞，这意味着一个或一组有限的线程可以在任何给定时间访问它们。这可能导致对这些共享数据结构的争用。高竞争本质上将导致访问共享数据结构的部分代码的执行序列化。

现代[的非阻塞并发算法](http://tutorials.jenkov.com/java-concurrency/non-blocking-algorithms.html)可以减少争用并提高性能，但是很难实现非阻塞算法。

持久数据结构是另一种选择。永久数据结构在修改后始终保留其自身的先前版本。因此，如果多个线程指向相同的持久数据结构，并且一个线程对其进行了修改，则修改线程将获得对新结构的引用。所有其他线程保留对旧结构的引用，该旧结构仍保持不变，因此是一致的。Scala编程包含几个持久数据结构。

虽然持久性数据结构是对共享数据结构进行并发修改的理想解决方案，但持久性数据结构往往无法很好地执行。

例如，一个持久列表会将所有新元素添加到列表的开头，并返回对新添加元素的引用（该引用随后指向列表的其余部分）。所有其他线程仍保留对列表中先前第一个元素的引用，并且对这些线程而言，列表保持不变。他们看不到新添加的元素。

这样的持久列表被实现为链接列表。不幸的是，链表在现代硬件上的表现不佳。列表中的每个元素都是一个单独的对象，这些对象可以分布在整个计算机的内存中。现代CPU顺序访问数据的速度要快得多，因此在现代硬件上，从阵列顶部实现的列表中可以获得更高的性能。数组顺序存储数据。CPU高速缓存可以一次将更大的阵列块加载到高速缓存中，并让CPU在加载后直接访问CPU高速缓存中的数据。对于链表，将元素分散在整个RAM上，这实际上是不可能的。





### 无国籍工人

共享状态可以由系统中的其他线程修改。因此，工作人员必须在需要时重新读取该状态，以确保该状态在最新副本上正常工作。无论共享状态是保留在内存中还是外部数据库中，都是如此。不在内部保持状态（但每次需要时都会重新读取*状态*）的工作程序称为*无状态*。

每次需要时重新读取数据都会变慢。特别是如果状态存储在外部数据库中。





### 作业排序是不确定的

并行工作程序模型的另一个缺点是作业执行顺序是不确定的。无法保证首先执行或最后执行哪些作业。作业A可以在作业B之前提供给工人，但作业B可以在作业A之前执行。

并行工作程序模型的不确定性使得很难在任何给定的时间点推断系统状态。这也使得很难（如果不是不可能的话）保证一项工作先于另一项工作发生。





## 流水线

第二种并发模型是我所说的*组装线*并发模型。我选择该名称只是为了适应早先的“并行工作者”隐喻。其他开发人员根据平台/社区使用其他名称（例如，反应系统或事件驱动的系统）。这是说明组装线并发模型的图：





工人的组织就像工厂中装配线的工人一样。每个工人仅完成全部工作的一部分。完成该部分后，工人会将工作转发给下一个工人。

每个工作程序都在自己的线程中运行，并且不与其他工作程序共享任何状态。有时也称为无*共享*并发模型。

使用组装线并发模型的系统通常设计为使用非阻塞IO。无阻塞IO意味着当工作人员开始IO操作（例如，从网络连接读取文件或数据）时，工作人员不会等待IO调用完成。IO操作很慢，因此等待IO操作完成会浪费CPU时间。同时，CPU可能正在做其他事情。IO操作完成后，IO操作的结果（例如，读取的数据或写入的数据的状态）将传递给另一个工作程序。

使用非阻塞IO，IO操作将确定工作线程之间的边界。在必须启动IO操作之前，工作人员将尽其所能。然后，它放弃了对工作的控制。IO操作完成后，装配线中的下一个工人将继续工作，直到必须开始IO操作等为止。





实际上，作业可能不会沿着一条装配线流动。由于大多数系统可以执行一项以上的工作，因此工作会根据需要完成的工作在一个工人之间流动。实际上，可能同时存在多个不同的虚拟装配线。这是现实中流水线系统中的工作流的样子：





甚至可以将作业转发给多个工人进行并行处理。例如，可以将作业转发给作业执行者和作业记录器。此图说明了三个装配线如何通过将其作业转发给同一工人（中间装配线中的最后一个工人）来完成：





流水线甚至比这还要复杂。





### 反应性，事件驱动系统

使用组装线并发模型的*系统*有时也称为*反应式系统*或 *事件驱动系统*。系统的工作人员会对系统中发生的事件做出反应，这些事件是从外界接收到的，或者是其他工作人员发出的。事件的示例可能是传入的HTTP请求，或者某个文件已完成加载到内存等。

在撰写本文时，有许多有趣的反应/事件驱动平台可用，将来还会有更多。一些更受欢迎的似乎是：

- [Vert.x](http://tutorials.jenkov.com/vert.x/index.html)
- 阿卡
- Node.JS（JavaScript）

我个人认为Vert.x非常有趣（特别是对于像我这样的Java / JVM恐龙）。





### 演员与频道

角色和通道是装配线（或反应/事件驱动）模型的两个类似示例。

在演员模型中，每个工人都称为*演员*。演员可以直接彼此发送消息。消息是异步发送和处理的。如前所述，可以使用Actor来实现一个或多个作业处理装配线。这是说明参与者模型的图：





在渠道模型中，工作人员不直接相互通信。相反，他们在不同的渠道上发布消息（事件）。然后，其他工作人员可以在这些频道上收听消息，而发件人不知道谁在收听。这是说明通道模型的图：





在撰写本文时，渠道模型对我来说似乎更灵活。工人不需要知道稍后在装配线中将处理什么工作的工人。它只需要知道将作业转发到哪个渠道（或将消息发送到等等）。频道上的侦听器可以订阅和取消订阅，而不会影响工作人员对频道的写入。这允许工人之间的联轴器稍松一些。





## 流水线优势

与并行工作程序模型相比，组装线并发模型具有多个优点。在以下各节中，我将介绍最大的优点。





### 没有共享状态

工作人员与其他工作人员不共享任何状态的事实意味着无需考虑并发访问共享状态可能引起的所有并发问题，就可以实现他们。这使实施工人变得容易得多。您将工作程序实现为好像是执行该工作的唯一线程-本质上是单线程实现。





### 有状态的工人

由于工作人员知道没有其他线程修改其数据，因此工作人员可以是有状态的。有状态的意思是他们可以将需要操作的数据保留在内存中，仅将更改写回最终的外部存储系统。因此，有状态工人通常比无状态工人更快。





### 更好的硬件整合

单线程代码的优势在于，它通常与底层硬件的工作方式更好地相符。首先，当您可以假定代码在单线程模式下执行时，通常可以创建更多优化的数据结构和算法。

其次，如上所述，单线程有状态工作者可以在内存中缓存数据。当数据缓存在内存中时，也更有可能将此数据也缓存在执行线程的CPU的CPU缓存中。这样可以更快地访问缓存的数据。

当以自然受益于底层硬件工作方式的方式编写代码时， 我将其称为*硬件一致性*。一些开发商称这种*机械同情*。我更喜欢“硬件一致性”一词，因为计算机几乎没有机械零件，并且在这种情况下，“同情”一词被用作“更好地匹配”的隐喻，我相信“符合”一词可以很好地传达。无论如何，这是挑剔的。使用您喜欢的任何术语。





### 可以订购工作

可以根据组装线并发模型以保证作业排序的方式实现并发系统。作业排序使在任何给定时间点推断系统状态变得更加容易。此外，您可以将所有传入的作业写入日志。然后，在系统的任何部分出现故障的情况下，可以使用此日志从头开始重建系统状态。作业以特定顺序写入日志，并且该顺序成为保证的作业顺序。这是这样的设计的外观：





实施保证的工作订单不一定很容易，但是通常是可能的。如果可以的话，它可以极大地简化备份，还原数据，复制数据等任务，因为所有这些都可以通过日志文件来完成。





## 组装线的缺点

组装流水线并发模型的主要缺点是，作业的执行通常分散在多个工作人员中，因此也分散在项目中的多个类中。因此，很难确切地知道给定作业正在执行什么代码。

编写代码也可能会更困难。辅助代码有时被编写为回调处理程序。具有许多嵌套回调处理程序的代码可能会导致某些开发人员称之为*回调地狱*。回调地狱只是意味着很难跟踪所有回调中代码的实际作用，以及确保每个回调都可以访问所需的数据。

使用并行工作程序并发模型，这往往会更容易。您可以打开工作程序代码，并从头到尾阅读几乎执行的代码。当然，并行工作程序代码也可以分布在许多不同的类上，但是执行顺序通常更容易从代码中读取。





## 功能并行

功能并行是第三种并发模型，最近（2015年）被广泛讨论。

函数并行性的基本思想是使用函数调用实现程序。功能可以看作是相互发送消息的“代理”或“角色”，就像在组装线并发模型（AKA反应或事件驱动系统）中一样。当一个函数调用另一个函数时，这类似于发送消息。

传递给函数的所有参数都将被复制，因此接收函数之外的任何实体都无法操纵数据。该复制对于避免共享数据出现争用情况至关重要。这使得函数执行类似于原子操作。每个函数调用都可以独立于任何其他函数调用执行。

当每个函数调用可以独立执行时，每个函数调用可以在单独的CPU上执行。这就是说，功能上实现的算法可以在多个CPU上并行执行。

使用Java 7，我们获得了`java.util.concurrent`包含[ForkAndJoinPool](http://tutorials.jenkov.com/java-util-concurrent/java-fork-and-join-forkjoinpool.html)的软件包，该软件包 可以帮助您实现类似于功能并行性的东西。使用Java 8，我们获得了并行[流](http://tutorials.jenkov.com/java-collections/streams.html) ，可以帮助您并行化大型集合的迭代。请记住，有些开发人员对此表示批评`ForkAndJoinPool`（您可以在本`ForkAndJoinPool`教程中找到批评的链接）。

关于函数并行性的难点是知道要并行调用哪些函数。跨CPU协调函数调用会带来开销。一个功能完成的工作单元必须具有一定的大小，才能负担此开销。如果函数调用很小，则尝试并行化它们实际上可能比单线程，单CPU执行慢。

根据我的理解（一点也不完美），您可以使用反应性，事件驱动的模型来实现算法，并实现类似于功能并行性的工作分解。使用均匀驱动的模型，您可以更好地控制要并行化的对象和数量（在我看来）。

另外，只有在该任务当前是程序唯一执行的任务时，才有意义地将任务分配给多个CPU，并产生开销。但是，如果系统正在同时执行多个其他任务（例如，Web服务器，数据库服务器和许多其他系统都在执行），则尝试并行化单个任务毫无意义。无论如何，计算机中的其他CPU都将忙于其他任务，因此没有理由尝试以较慢的，功能上并行的任务来打扰它们。组装流水线（反应式）并发模型可能会更好，因为它具有较少的开销（以单线程模式顺序执行），并且与底层硬件的工作方式更好地兼容。





## 哪种并发模型最好？

那么，哪种并发模型更好？

通常，答案是这取决于系统应该执行的操作。如果您的工作自然是并行的，独立的并且不需要共享状态，则可以使用并行工作器模型来实现系统。

但是，许多工作并非自然而然地平行和独立。对于这些类型的系统，我相信组装线并发模型的优点要大于缺点，比并行工作器模型要有更多的优点。

您甚至不必自己编写所有组装线基础结构的代码。像[Vert.x](http://tutorials.jenkov.com/vert.x/index.html)这样的现代平台 已经为您实现了很多功能。我个人将为下一个项目探索在Vert.x等平台上运行的设计。我觉得Java EE不再具有优势。